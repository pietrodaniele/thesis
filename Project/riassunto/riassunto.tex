\documentclass[a4paper, oneside, 11pt]{book}

\usepackage[a-1b]{pdfx}
\usepackage{geometry,url,graphicx, hyperref,subfig,enumitem, amsmath,float}
\usepackage{amsmath, amssymb, amsthm, mathtools, color, setspace}
\usepackage{fancyhdr, braket, etoolbox,booktabs,multirow}
\usepackage{xfrac, lmodern, ifsym, bm} % xfrac gives font errors, add lmodern to remove them. Check whether this remains a problem!
%\usepackage{hyperref}
%\usepackage[utf8]{inputenc}
%\usepackage{colorprofiles}
\usepackage[T1]{fontenc}

\begin{document}
	This thesis presents the search for new resonances in the 105 to 200 GeV diphoton invariant mass range using 140 fb$^{-1}$ of $pp$ collisions collected at $\sqrt{s}$=13 TeV with the ATLAS detector at the Large Hadron Collider (LHC). The LHC \cite{LHC_DESIGN_2004,LHC_DESIGN_2008} is a superconducting two-ring, protons and heavy ions collider installed in the 27 km-long LEP \cite{LEP_DESIGN_2001} tunnel at CERN in Geneve. It provides $pp$ collisions at an unprecedent center of mass energy $\sqrt{s}$ = 13 TeV. Four experiments are installed in the LHC interaction points to analyse the particles produced by the collisions in the accelerator. Each experiment is characterized by a peculiar design optimized on its specific physics program.
	
	This thesis is performed within the ATLAS \cite{ATLAS_DESIGN_2008} experiment. The ATLAS detector covers nearly the entire solid angle around the collision point. It consists of an inner tracking detector surrounded by a thin superconducting solenoid, electromagnetic and hadronic calorimeters, and a muon spectrometer incorporating three large superconducting toroidal magnets. The ATLAS experiment is designed to explore a wide range of physics topics, with the primary focus of improving our understanding of the fundamental constituents of matter and their interactions. Currently particle physics phenomenology is well described by the so called Standard Model (SM), a quantum field theory based on SU(2)$\otimes$U(1)$\otimes$SU(3) gauge symmetry \cite{weinberg_1995}. In particular, the SM predicted a new particle, the Higgs boson (Higgs$_{125}$) \cite{higgs_atlas,higgs_cms}, that was discovered by the ATLAS and CMS Collaborations in 2012.
	
	However the SM in not the final theory, since, for example, it provides no dark matter candidate and no explanation for the matter-antimatter asymmetry in the universe, so there must be physics beyond the Standard Model (BSM). One possibility for new physics to show up is through an extension of the Higgs field that forms in the SM a complex doublet under the weak isospin SU(2) symmetry group could be extended. Larger scalar sectors that include a boson consistent with the Higgs$_{125}$ observation typically incorporate this complex doublet and add additional structure, predicting new bosons. The extended Higgs sector can be embedded in a larger theoretical scenario, such as a two-Higgs-doublet model (2HDM)\cite{Branco_2012}, or supersymmetry (SUSY) \cite{dine_2016}.
	
	One of the most important signatures for many physics analyses envisaged at the ATLAS experiment is final state containing photons. Excellent performance in the photons reconstruction is essential to exploit the full physics potential of the ATLAS detector, both in searches for new physics and in precision measurements. Photons are reconstructed starting from energy deposits in the electromagnetic calorimeter and tracks from inner detector hits, as described in \cite{Aad_2019}, and these reconstructed objects are selected using momentum and quality cuts. This thesis focuses on the search for new spin-0 resonances in the 105 to 200 GeV diphoton invariant mass range using 140 fb$^{-1}$ of $pp$ collisions collected at $\sqrt{s}$=13 TeV with the ATLAS detector. The selected events, in order to enhance the analysis sensitivity are then classified into mutually exclusive categories. Different categorisations are tested and compared with each other: \texttt{Inclusive}, in which there is only one category which contains all selected events, \texttt{catConvEta}, which classifies the events in 6 different categories based on $\gamma$ conversion status and $\eta$ position, and \texttt{catConv}, which separates the events using $\gamma$ conversion status in two different categories.
	
	For each category the signal and backgrounds are modelled using analytic functions of $m_{\gamma\gamma}$, using simulated events (Figure \ref{fig:mass_inv}). The signal model is parametrised as a function of the mass of the resonance. The signal is modelled starting from simulated SM Higgs to two photons events with different mass values. In order to reduce the dependence of the analysis from SM assumptions only \textit{ggF} MC samples of SM (spin0) Higgs bosons decaying into two photons are used. The new spin-0 resonances sensitivity has been tested with positive results. The variation for efficiency selections for other production modes, which contribute to Higgs$_{125}$ SM production, is included as a systematic uncertainty on the signal yield. The non-resonant background is composed by mainly the non-resonant production of photon pairs ($\gamma\gamma$ events) and by smaller components that come from events containing a photon and a jet ($\gamma j$ events) and events with two jets ($jj$ events), where the jets are misidentified as photons. This background in each category is described by a smoothly falling function whose normalization and shape parameters will be determined data. In order to investigate the presence of new spin-0 resonances, the SM Higgs$_{125}$ is also included as background, describing it with fixed resonant function.
	\begin{figure}
		\centering
		\includegraphics[width=.8\textwidth]{../thesis_images/HSM_prova.pdf}
		\caption{The distributions of the invariant mass of the Asimov dataset with $\mu$=1 and $m_X$=140 GeV, which is composed by signal, non-resonant background and HSM background, for the \texttt{Inclusive} categorisation. The pdfs, used the creation of the Asimov, are fitted on it and plotted on top of it.}
		\label{fig:mass_inv}
	\end{figure}
	
	Once, using the selected events of MC samples, the different categorisation are applied and the models are created, a combined maximum likelihood fit in all the categories is performed to investigate the presence of a signal by computing the compatibility of the observed data with the background-only hypothesis $p_0$ \cite{Statistic} (Figure \ref{fig:p0}) and assessing limits \cite{Statistic} (Figure \ref{fig:limits}) on the production cross-section in case no excess of signal is observed.
	\begin{figure}
		\centering
		\includegraphics[width=.8\textwidth]{../thesis_images/p0_no_catConvEta.pdf}
		\caption{Expected $p_0$ values and observed ones values obtained by using Asimov dataset with $\mu$=1 and m$_X$ = 125 (140) GeV, for \texttt{Inclusive} categorisation, as function of $m_X$.}
		\label{fig:p0}
	\end{figure}
	\begin{figure}
		\centering
		\includegraphics[width=.8\textwidth]{../thesis_images/plot_AsimovData_0_ggHyy_MC_no_catConvEta_syst_HSM_fid_nom_gaus.pdf}
		\caption{95\% CL$_S$ upper limits plots for the \texttt{Inclusive} categorisation, as function of $m_X$.}
		\label{fig:limits}
	\end{figure}Using this fit results, the different categorisation performances are evaluated and compared. When no systematic uncertainties are included in the fit, \texttt{catConvEta} (\texttt{catConv}) categorisation results an $+0.718\sigma$ ($+0.14\sigma$) improvement in the discovery potential, and in a  X\% (Y\%) enhancement in limits setting, compared to \texttt{Inclusive} category. But since the other production modes systematic uncertainty increases in the more granular categorisation, the discovery potential and limits setting decrease. So, with the effect of all systematic uncertainties inserted in the analysis, looking at 95\% CL$_S$ limits, the best categorisation is the \texttt{catConvEta} that shows an always positive improvement in the exclusion performance reaching its maximum value 4.2\% at $m_X$ = 170 GeV. On the contrary, the \texttt{catConv} categorisation should be discarded as it is not able to bring a consistently positive improvement on the limits compared to \texttt{Inclusive} over the $m_{\gamma\gamma}$ range.
	
	In conclusion, the potential of search for new resonances in [105,200] $m_{\gamma\gamma}$ range using 140 fb$^{-1}$ of $pp$ collisions collected at $\sqrt{s}$=13 TeV with the ATLAS detector, has been investigated in this thesis. The best categorisation obtained from the trade-off between performances and model SM independence is \texttt{catConvEta}. The analysis is still blind so no results based on data have been shown. The results presented in this thesis represent the first step towards the unblinding. Therefore this configuration should be the starting point for further development of the analysis, such as the spurious signal study or, once completed, its application to ATLAS observed data.
	
	%The Higgs field in the SM forms a complex doublet under the weak isospin SU(2) symmetry group. Larger scalar sectors that include a boson consistent with the Higgs$_{125}$ observation typically incorporate this complex doublet and add additional structure. So the extended Higgs sector can be embedded in a larger theoretical scenario, such as a two-Higgs-doublet model (2HDM)\cite{Branco_2012}, or supersymmetry (SUSY) \cite{dine_2016}, or it can be extended to include dark matter candidates.
	
	%Events with photons in the final state are important signatures for many physics analyses envisaged at the ATLAS experiment: excellent performance in the  photons reconstruction is essential to exploit the full physics potential of the detector, both in searches for new physics and in precision measurements. In particular, this thesis focuses on the search for new resonances in the 105 to 200 GeV diphoton invariant mass range using 140 fb$^{-1}$ of $pp$ collisions collected at $\sqrt{s}$=13 TeV with the ATLAS detector. Therefore the analysis is based on photons, which in ATLAS are reconstructed starting from energy deposits in the electromagnetic calorimeter and tracks from inner detector hits, as described in \cite{Aad_2019}. These reconstructed object are included in the analysis through the selection of pairs of high-$p_T$ and isolated photons \cite{Aad_2019}. These selected events are then classified into mutually exclusive categories designed to enhance the analysis sensitivity. Different categorisations are tested and compared with each other.	
	
	%The signal in each category is defined as a function of the mass of the resonance and its model is created using simulated MC samples of SM (spin0) Higgs bosons decaying into two photons. The background in each category is described by a smoothly falling function whose normalization and shape parameters will be determined from MC samples. Since the model must be SM independent in order to investigate the presence of new spin-0 resonances, the SM Higgs 125 is also included as background. A combined maximumlikelihood fit in all the categories is performed to investigate the presence of a signal bycomputing the compatibility of the observed data with the background-only hypothesis. Looking at limits on the signal cross for each models built with different categorisation,the best working point is selected.
	
	%In questa analisi modello indipendente dalla SM
	
	%una volta che le categorie sono state applicate e i modelli creati A combined maximum likelihood fit in all the categories is performed to investigate the presence of a signal by computing the compatibility of the observed data with the background-only hypothesis. guardando a questi limiti si comparano le categorie tenendo conto anche della model indepndence
	
	
	
	
	\iffalse
	Electrons and photons in ATLAS are reconstructed starting from energy deposits in the electromagnetic calorimeter and tracks from inner detector hits. An electron is defined as an object consisting of a cluster built from energy deposits in the calorimeter with a track pointing to it. A converted photon is a cluster matched to a conversion vertex, and an unconverted photon is a cluster matched to neither a track or a conversion vertex. The $e$ and $\gamma$ are reconstructed independently, so it is possible to reconstruct $e$ or $\gamma$ from the same clusters and tracks. After the $e/\gamma$ are reconstructed, an ambiguity resolver algorithm is applied on them: if a particular object can be easily identified only as a photon (a cluster with no good track attached) or only as an electron (a cluster with a good track attached and no good photon conversion vertex), then only a photon or an electron object is stored for analysis; otherwise, both an electron and a photon object are created. At the reconstruction level only simple algorithms are used. They resolve only the simplest cases whereas many objects are flagged as ambiguous, leaving the final arbitration at the analysis level. The ambiguous objects classification can be approached with machine learning techniques, which provide better results with respect to simple cut-based selections. In particular in this thesis the usage of a supervided learning algorithm, called Gradient Boosted  Decision Tree (GBDT) has been studied.
	
	Typically the reconstruction algorithm provides both electron and photon candidates in $\sim$8\% of the \textit{True electrons} and $\sim$31\% of the \textit{True photons}. In this thesis three main scenarios are investigated. The first case is a classification of all doubly reconstructed objects, creating a model trained on them. It explores the possibility to replace the current classification algorithm with a gradient boosted decision tree for all electrons and photons candidates with no pre-classification from ambiguity resolver. This model achieves an AUC of $\sim0.9958$. The \textit{double reconstruction} model sets the theoretical limit because this approch can not be used in standard data reconstruction due to the enormous memory cost of saving all objects as doubly reconstructed. To reduce double reconstructions to be saved, a loose resolution is applied: firstly the standard ambiguity (\textit{old amb}) resolver used in Run 2 data taking was investigate, secondly a more optimized resolver (\textit{new amb}) foreseen for the upcoming Run 3 is studied. Two new models are trained on top of the particles classified as ambiguous by these simple tools and they can also achieve excellent particle classification capabilities. In these cases the \textit{old amb} model, which has been trained on objects flagged as “ambiguous” by the old ambiguity tool, achieves an AUC of $\sim0.9808$, whereas the AUC of the \textit{new amb} model, which is based on the new ambiguity tool, is equal to $\sim0.9907$. The new ambiguity tool increases the performance of a GBDT based on ambiguous objects, allowing a better classification efficiency and a higher photon efficiency than the old one: if the photon efficiency $\epsilon_{ph}$ is fixed the difference between the electron efficiencies $\epsilon_{el}^{new} - \epsilon_{el}^{old}$ is in its maximum value equal to $\sim$ 7\%; on the contrary if the electron efficiency $\epsilon_{el}$ is fixed the difference between the photon efficiencies $\epsilon_{ph}^{new} - \epsilon_{ph}^{old}$ is in its maximum value equal to $\sim$ 3\%.
	
	As shown by these results, models trained on ambiguous objects flagged by ambiguity tools are able to achieve very good performance in classification. In particular, with the introduction of the new ambiguity tool, performance has improved since the ambiguous photons are increased allowing the BDT algorithm to reach the theoretical limit. Moreover, these two models can be used at the analysis level to classify ambiguous objects. In fact, the analyses are now flagging all the ambiguous objects as all electrons or all photons, while a GBDT provides a continuous score for them which allows for an optimal choice based on analysis needs.
	\fi
	\newpage
	\bibliography{../biblio.bib}
	\bibliographystyle{unsrturl}
	
\end{document}